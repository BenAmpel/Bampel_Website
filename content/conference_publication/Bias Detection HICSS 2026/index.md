---
title: 'A Domain-Adaptive Soft Prompting Framework for Multi-Type Bias Detection in News'

authors:
  - Chengjun Zhang
  - admin
  - Sagar Samtani

date: '2026-01-06T00:00:00Z'
doi: '10.24251/HICSS.2026.218'

publishDate: '2026-01-06T00:00:00Z'

publication_types: ['1']

publication: In *Proceedings of the 59th Hawaii International Conference on System Sciences (HICSS)*
publication_short: In *HICSS*

abstract: Advances in Large Language Models (LLMs) have enabled new opportunities to automate media analysis and improve collaborative social cybersecurity. A key task is bias detection in news reporting, which is essential for promoting information fairness and reducing polarization. However, existing approaches often rely on supervised fine-tuning with labeled datasets and fail to capture domain-specific linguistic patterns, limiting scalability and generalization. To address this, we propose a lightweight, modular framework that combines domain-adaptive pretraining (DAP) with Masked Language Modeling (MLM) and soft prompt tuning to detect six types of media bias (framing, group, semantic properties, connotation, informational spin, and phrasing). Our framework leverages 401,000+ New York Times articles from 2000 to 2024 to pretrain five LLMs, followed by bias prompting with small labeled data. The approach improves F1 by 7.6% and precision by 6.8% over hard prompts on average across the six types of biases.

tags:
- Bias Detection
- Media Bias
- Large Language Models
- Soft Prompting
- Domain-Adaptive Pretraining
- Natural Language Processing

featured: false

url_pdf: 'https://hdl.handle.net/10125/111610'
---

<div class="altmetric-badge" style="display: inline-block; margin: 20px 0;">
  <div data-badge-type="medium-donut" data-doi="10.24251/HICSS.2026.218" data-badge-popover="right" class="altmetric-embed"></div>
</div>
